-- Asteroid implementation of a simple calculator language
-- The interpreter will read an expression from stdin and output is
-- written to stdout.  The program
--   (2+3)*2
-- will print the value 10.  In order to terminate interactively
-- provided input you will have to type <CR><Cntrl-D>
-- Lutz Hamel, (c) University of Rhode Island

load "io".
load "lexer".

-------------------------------------------------------------------------
-- A recursive descent parser implementing the following grammar:
-- <expression> ::= <mulexp> { ('+' <mulexp>) | ('-' <mulexp>) }
-- <mulexp>     ::= <rootexp> { ('*' <rootexp>) | ('/' <rootexp>) }
-- <rootexp>    ::= number | '-' <rootexp> | '(' <expression> ')'
-- The parser implements arithmetic on integer values

function expression
  with lexer:%Lexer do
    let val = mulexp(lexer).
    loop do
      let token = lexer @peek().
      if not token do
        break.
      elif token @type == "add" do
        lexer @token_match("add").
        let val = val + mulexp(lexer).
      elif token @type == "sub" do
        lexer @token_match("sub").
        let val = val - mulexp(lexer)
      else do
        break.
      end
    end
    return val.
  end

function mulexp
  with lexer:%Lexer do
    let val = rootexp(lexer).
    if not lexer @peek() do
      return val.
    end
    loop do
      let token = lexer @peek().
      if not token do
        break.
      elif token @type == "mul" do
        lexer @token_match("mul").
        let val = val * rootexp(lexer).
      elif token @type == "div" do
        lexer @token_match("div").
        let val = val / rootexp(lexer)
      else do
        break.
      end
    end
    return val.
  end

function rootexp
  with lexer:%Lexer do
    try
      let Token(type,val) = lexer @peek().
    catch _ do
      return none.
    end
    if type == "number" do
      lexer @token_match("number").
      return val.
    elif type == "sub" do
      lexer @token_match("sub").
      return - rootexp(lexer).
    elif type == "lparen" do
      lexer @token_match("lparen").
      let val = expression(lexer).
      lexer @token_match("rparen").
      return val.
    else do
      throw Error("syntax error at token "+val).
    end
  end

-------------------------------------------------------------------------
-- driver part of the script

-- tokenize input
let input = read().
let lexer = Lexer(tokenize(input)).

-- parse and interpret input
let val = expression(lexer).
if not (lexer @eof()) do
  throw Error("tokens still in input stream")
end

-- print out the final value of the parsed and interpreted expression
println ("=> "+val).
